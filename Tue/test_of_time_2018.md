# NeurIPS 2018 Test of Time Award

## Test of Time Paper

[The Tradeoffs of Large Scale Learning](https://leon.bottou.org/publications/pdf/mloptbook-2011.pdf)

## Key Contributions

* Approximation-Optimization-Estimation Trade-offs
* If resource is limited but data scale is huge, stochastic gradient descent
  (SGD) is a good method to train your model using a small batch of data and
  use it in an iterative way.

Recording can be found [here](https://www.facebook.com/nipsfoundation/videos/271569366878864/) around 56min marker.