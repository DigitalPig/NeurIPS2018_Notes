# Talks

## Almost Optimal Algorithms for Linear StochasticBandits with Heavy-Tailed Payoffs

Slide can be found [here](https://nips.cc/media/Slides/nips/2018/220cd(05-09-45)-05-09-50-12623-Almost_Optimal_.pdf)


## Nearly tight sample complexity bounds for learning mixtures of Gaussian via sample compression schemes

Paper can be found
[here](https://papers.nips.cc/paper/7601-nearly-tight-sample-complexity-bounds-for-learning-mixtures-of-gaussians-via-sample-compression-schemes).

## A loss framework for calibrated anomaly detection

Given samples from a probability distribution, anomaly detection is the problem
of determining if a given point lies in a low-density region. This paper
concerns calibrated anomaly detection, which is the practically relevant
extension where we additionally wish to produce a confidence score for a point
being anomalous. Building on a classification framework for anomaly detection,
we show how minimisation of a suitably modified proper loss produces density
estimates only for anomalous instances. We then show how to incorporate
quantile control by relating our objective to a generalised version of the
pinball loss. Finally, we show how to efficiently optimise the objective with
kernelised scorer, by leveraging a recent result from the point process
literature. The resulting objective captures a close relative of the one-class
SVM as a special case.

Paper can be downloaded
[here](https://papers.nips.cc/paper/7422-a-loss-framework-for-calibrated-anomaly-detection)


## The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal

Presentation slide is
[here](https://nips.cc/media/Slides/nips/2018/517cd(05-15-30)-05-15-30-12685-The_Nearest_Nei.pdf).
Paper can be found [here](https://arxiv.org/abs/1711.08824).

## Contextual Stochastic Block Models

Presentation slide is
[here](https://nips.cc/media/Slides/nips/2018/517cd(05-15-30)-05-15-35-12686-Contextual_Stoc.pdf)
and the paper can be found [here](https://arxiv.org/abs/1807.09596).

A method to combine clustering and feature gathering together. And authors
provide a theoretical proof for the tight bound of the method.

## Entropy Rate Estimation for Markov Chains with Large State Space

Presentation can be found
[here](https://nips.cc/media/Slides/nips/2018/517cd(05-15-30)-05-15-40-12687-Entropy_Rate_Es.pdf)
and the paper can be found [here](https://arxiv.org/abs/1802.07889).

## Policy Optimization via Importance Sampling

Paper can be found [here](https://arxiv.org/abs/1809.06098). Recording of the presentation can be found [here](https://www.facebook.com/nipsfoundation/videos/198568127715251/) at 25:45min place.

Authors' code can be downloaded from [here](https://github.com/T3p/pois). And
documentation can be found [here](https://t3p.github.io/neurips18/).

## Randomized Prior Functions for Deep Reinforcement Learning

Paper can be found [here](https://arxiv.org/abs/1806.03335). Slide can be
downloaded from
[here](https://nips.cc/media/Slides/nips/2018/220cd(05-15-30)-05-16-15-12662-Randomized_Prio.pdf)

## Visual Reinforcement Learning with Imagined Goals

Presentation slide can be downloaded from [here](https://nips.cc/media/Slides/nips/2018/220cd(05-15-30)-05-16-10-12661-Visual_Reinforc.pdf)

Authors release the code in this github
[repo](https://github.com/vitchyr/rlkit).

## Recurrent World Models Facilitate Policy Evolution

Authors have a nice [website](https://worldmodels.github.io/) to demo their
main concepts. Basically, a universal model of RL.

## On Coresets for Logistic Regression

Paper can be downloaded from [here](https://arxiv.org/abs/1805.08571).